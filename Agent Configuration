# Agent Configuration Guide

## Overview

Agent features are **required** for search functionality. The agent handles natural language query interpretation and rewriting. This guide shows exactly what configuration is needed.

---

## Required Configuration

### Step 1: Enable Agent

```bash
AGENT_ENABLED=true
```

### Step 2: Choose and Configure LLM Provider

Choose **ONE** of the following options:

---

## Option 1: OpenAI (Recommended for Production)

### Required Variables

```bash
AGENT_ENABLED=true
LLM_PROVIDER=openai
LLM_MODEL=gpt-3.5-turbo          # or gpt-4, gpt-4-turbo-preview
OPENAI_API_KEY=sk-your-api-key-here
```

### Optional Variables

```bash
OPENAI_BASE_URL=https://api.openai.com/v1  # Default if not specified
LLM_TEMPERATURE=0.3                        # Default: 0.3
LLM_MAX_TOKENS=500                         # Default: 500
```

### Getting OpenAI API Key

1. Sign up at https://platform.openai.com
2. Go to API Keys section
3. Create a new secret key
4. Copy and use as `OPENAI_API_KEY`

### Complete Example

```bash
# .env file
AGENT_ENABLED=true
LLM_PROVIDER=openai
LLM_MODEL=gpt-3.5-turbo
OPENAI_API_KEY=sk-proj-abc123xyz789...
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
```

---

## Option 2: Azure OpenAI (Enterprise)

### Required Variables

```bash
AGENT_ENABLED=true
LLM_PROVIDER=azure
LLM_MODEL=your-deployment-name             # e.g., gpt-35-turbo
AZURE_OPENAI_API_KEY=your-azure-api-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
```

### Optional Variables

```bash
AZURE_OPENAI_API_VERSION=2024-02-15-preview  # Default if not specified
LLM_TEMPERATURE=0.3                           # Default: 0.3
LLM_MAX_TOKENS=500                            # Default: 500
```

### Getting Azure OpenAI Credentials

1. Create an Azure OpenAI resource in Azure Portal
2. Deploy a model (e.g., gpt-35-turbo)
3. Get API key from "Keys and Endpoint" section
4. Get endpoint URL (format: `https://YOUR-RESOURCE.openai.azure.com`)
5. Note your deployment name

### Complete Example

```bash
# .env file
AGENT_ENABLED=true
LLM_PROVIDER=azure
LLM_MODEL=gpt-35-turbo
AZURE_OPENAI_API_KEY=abc123def456...
AZURE_OPENAI_ENDPOINT=https://my-ai-resource.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-02-15-preview
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
```

---

## Option 3: Ollama (Local - Free)

### Required Variables

```bash
AGENT_ENABLED=true
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434     # Default if not specified
OLLAMA_LLM_MODEL=llama2                    # or mistral, codellama, etc.
```

### Optional Variables

```bash
LLM_TEMPERATURE=0.3                        # Default: 0.3
LLM_MAX_TOKENS=500                         # Default: 500
```

### Setting Up Ollama

1. Install Ollama: https://ollama.ai
2. Pull a model:
   ```bash
   ollama pull llama2
   # or
   ollama pull mistral
   # or
   ollama pull codellama
   ```
3. Start Ollama (usually runs automatically)
4. Verify it's running: `curl http://localhost:11434/api/tags`

### Complete Example

```bash
# .env file
AGENT_ENABLED=true
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_LLM_MODEL=llama2
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
```

---

## Configuration Parameters Explained

### AGENT_ENABLED
- **Required**: `true` or `false`
- **Purpose**: Enables/disables agent features
- **Note**: Must be `true` for search to work

### LLM_PROVIDER
- **Required**: `openai`, `azure`, or `ollama`
- **Purpose**: Selects which LLM provider to use

### LLM_MODEL
- **Required**: Model name/deployment name
- **Purpose**: Which model to use for queries
- **Examples**:
  - OpenAI: `gpt-3.5-turbo`, `gpt-4`
  - Azure: Your deployment name (e.g., `gpt-35-turbo`)
  - Ollama: Model name (e.g., `llama2`, `mistral`)

### LLM_TEMPERATURE
- **Optional**: Default `0.3`
- **Range**: 0.0 to 2.0
- **Purpose**: Controls randomness in responses
  - Lower (0.0-0.3): More deterministic, focused
  - Higher (0.7-2.0): More creative, varied
- **Recommendation**: 0.3 for query interpretation (more consistent)

### LLM_MAX_TOKENS
- **Optional**: Default `500`
- **Purpose**: Maximum tokens in LLM response
- **Recommendation**: 500 is usually sufficient for query interpretation

### Provider-Specific Variables

#### OpenAI
- `OPENAI_API_KEY`: Your OpenAI API key (required)
- `OPENAI_BASE_URL`: API endpoint (optional, defaults to OpenAI)

#### Azure OpenAI
- `AZURE_OPENAI_API_KEY`: Your Azure API key (required)
- `AZURE_OPENAI_ENDPOINT`: Your Azure endpoint URL (required)
- `AZURE_OPENAI_API_VERSION`: API version (optional, has default)

#### Ollama
- `OLLAMA_BASE_URL`: Ollama server URL (optional, defaults to localhost:11434)
- `OLLAMA_LLM_MODEL`: Model name to use (required)

---

## Complete .env File Example

### For Development (OpenAI)

```bash
# Core Service Config
ENVIRONMENT=dev
API_PREFIX=/api/v1
VECTOR_TOP_K=20

# Qdrant Vector Store
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Embeddings
EMBEDDING_PROVIDER=ollama
EMBEDDING_DIM=768
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBED_MODEL=all-minilm:16-v2

# Agent Configuration (OpenAI)
AGENT_ENABLED=true
LLM_PROVIDER=openai
LLM_MODEL=gpt-3.5-turbo
OPENAI_API_KEY=sk-proj-your-key-here
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
```

### For Production (Azure OpenAI)

```bash
# Core Service Config
ENVIRONMENT=prod
API_PREFIX=/api/v1
VECTOR_TOP_K=20

# Qdrant Vector Store (Cloud)
QDRANT_URL=https://your-cluster.qdrant.io
QDRANT_API_KEY=your-qdrant-key

# Embeddings (Azure OpenAI)
EMBEDDING_PROVIDER=azure
EMBEDDING_DIM=1536

# Agent Configuration (Azure OpenAI)
AGENT_ENABLED=true
LLM_PROVIDER=azure
LLM_MODEL=gpt-35-turbo
AZURE_OPENAI_API_KEY=your-azure-key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-02-15-preview
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
```

### For Local Development (Ollama)

```bash
# Core Service Config
ENVIRONMENT=dev
API_PREFIX=/api/v1
VECTOR_TOP_K=20

# Qdrant Vector Store
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Embeddings (Ollama)
EMBEDDING_PROVIDER=ollama
EMBEDDING_DIM=768
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBED_MODEL=all-minilm:16-v2

# Agent Configuration (Ollama - Local)
AGENT_ENABLED=true
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_LLM_MODEL=llama2
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
```

---

## Verification

### Test Agent Configuration

```bash
# Check if agent is enabled and configured
curl -X POST "http://localhost:8000/api/v1/search/interpret?query=test&search_type=jobs"
```

### Expected Behavior

**If configured correctly:**
- Returns interpreted query with extracted filters

**If not configured:**
- Returns 503 Service Unavailable with error message

### Common Issues

1. **"Agent features are not enabled"**
   - Set `AGENT_ENABLED=true`

2. **"LLM client is not enabled or not configured"**
   - Check API key is set correctly
   - Verify provider matches your credentials
   - For Azure: Check endpoint URL format

3. **Connection errors (Ollama)**
   - Ensure Ollama is running: `ollama serve`
   - Check `OLLAMA_BASE_URL` is correct
   - Verify model is installed: `ollama list`

---

## Cost Considerations

### OpenAI
- **GPT-3.5-turbo**: ~$0.0001-0.0005 per search query
- **GPT-4**: ~$0.003-0.01 per search query
- **Recommendation**: Use GPT-3.5-turbo for cost-effectiveness

### Azure OpenAI
- Similar pricing to OpenAI
- Enterprise-grade SLA and compliance

### Ollama
- **Cost**: Free (runs locally)
- **Requires**: Local GPU/CPU resources
- **Best for**: Development, testing, privacy-sensitive use cases

---

## Quick Reference

### Minimum Required Configuration

**OpenAI:**
```bash
AGENT_ENABLED=true
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-...
```

**Azure:**
```bash
AGENT_ENABLED=true
LLM_PROVIDER=azure
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_ENDPOINT=https://...
```

**Ollama:**
```bash
AGENT_ENABLED=true
LLM_PROVIDER=ollama
OLLAMA_LLM_MODEL=llama2
```

---

## Next Steps

1. Choose your provider
2. Set required environment variables
3. Create `.env` file in project root
4. Restart the service
5. Test with a search query

For more details, see:
- `AGENT_FEATURES_GUIDE.md` - Usage guide
- `README.md` - General service documentation

